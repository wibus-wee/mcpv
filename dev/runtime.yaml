routeTimeoutSeconds: 10
pingIntervalSeconds: 30
toolRefreshSeconds: 60
toolRefreshConcurrency: 4
callerCheckSeconds: 5
callerInactiveSeconds: 300
serverInitRetryBaseSeconds: 1
serverInitRetryMaxSeconds: 30
serverInitMaxRetries: 5
exposeTools: true
toolNamespaceStrategy: "prefix"
observability:
  listenAddress: "0.0.0.0:9090"
# rpc:
#   listenAddress: "tcp://0.0.0.0:9091"
#   maxRecvMsgSize: 16777216
#   maxSendMsgSize: 16777216
#   keepaliveTimeSeconds: 30
#   keepaliveTimeoutSeconds: 10
#   socketMode: "0660"
#   tls:
#     enabled: false
#     certFile: ""
#     keyFile: ""
#     caFile: ""
#     clientAuth: false

# SubAgent LLM Provider Configuration (runtime-level, shared across all profiles)
# Per-profile enabling is done in profiles/xxx.yaml with subAgent.enabled: true
subAgent:
  model: "gpt-4o"
  provider: "openai"
  # apiKey: ""  # Optional: inline API key (avoid committing secrets)
  # apiKeyEnvVar: "OPENAI_API_KEY"
  # baseURL: ""  # Optional: custom API endpoint
  maxToolsPerRequest: 20
  # filterPrompt: ""  # Optional custom prompt for tool filtering
